{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "predictive_analysis_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA3giDhQ666Q"
      },
      "source": [
        "# DATA MINING PROJECT: Analysis of a Supermarketâ€™s Customers\n",
        "## 3.2) Predictive Analysis: classification\n",
        "### *Antonio Strippoli, Valerio Mariani*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS-ynrU3666Q"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('mode.chained_assignment', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QstT2z98666R"
      },
      "source": [
        "def plot(ax, folder=\"predictive\", filename=\"\", figsize=(6.4, 4.8)):\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(*figsize)\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        path = os.path.join(\"..\", \"report\", \"imgs\", folder)\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "        plt.savefig(os.path.join(path, filename))\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7J1vudNOjY2"
      },
      "source": [
        "#evaulate the accuracy on the train set and the test set\n",
        "#metrics also contains precision, recall, f1 and the support\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "def compute_scores(estimator, train_set, test_set, train_label, train_pred, test_label, test_pred):\n",
        "  train = True\n",
        "  for label, pred in zip([train_label, test_label], [train_pred, test_pred]):\n",
        "    if train:\n",
        "      print(\"=== TRAINING SET ===\")\n",
        "      train = False\n",
        "    else:\n",
        "      print(\"\\n=== TEST SET ===\")\n",
        "    print('Accuracy:', metrics.accuracy_score(label, pred))\n",
        "    print('Precision:', metrics.precision_score(label, pred, average='weighted'))\n",
        "    print('Recall:', metrics.recall_score(label, pred, average='weighted'))\n",
        "    print('F1 Score:', metrics.f1_score(label, pred, average='weighted'))\n",
        "    print('Support:', metrics.precision_recall_fscore_support(label, pred))\n",
        "  \n",
        "  print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
        "  print(metrics.classification_report(\n",
        "      test_label,\n",
        "      test_pred,\n",
        "      target_names=['low-spending', 'medium-spending', 'high-spending']\n",
        "    )\n",
        "  )\n",
        "\n",
        "  if estimator:\n",
        "    print(\"\\n=== CONFUSION MATRIX ===\")\n",
        "    metrics.plot_confusion_matrix(estimator, test_set, test_label)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKRTzkrfMj8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76ee61d-ed82-4a8a-b946-6076dfe4f71d"
      },
      "source": [
        "# Split the dataset into training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset and set hyper-parameter\n",
        "cldf = pd.read_csv(\"customer_classification.csv\", index_col=0)\n",
        "oversampling = True\n",
        "\n",
        "# Extract labels and normalize values\n",
        "label = cldf.pop('Labels')\n",
        "X = MinMaxScaler().fit_transform(cldf.values)\n",
        "\n",
        "# Prepare training set and test set\n",
        "cldf = pd.DataFrame(X, columns=cldf.columns)\n",
        "train_set, test_set, train_label, test_label = train_test_split(cldf, label, stratify=label, test_size=.3)\n",
        "\n",
        "# Perform oversampling?\n",
        "if oversampling == True:\n",
        "  train_set, train_label = SMOTE(random_state=22).fit_sample(train_set, train_label)\n",
        "  train_set = pd.DataFrame(train_set, columns=cldf.columns)\n",
        "  train_label = pd.DataFrame(train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCORC0QUwctu"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "FR7E69Y67b-K",
        "outputId": "905c3bb8-cea9-4dfa-cbb6-79c1d5bc2edc"
      },
      "source": [
        "# We define a Decision Tree based on the result of a Grid Search\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Model validation\n",
        "params = {\n",
        "    'criterion': ['gini','entropy'],\n",
        "    'max_depth': list(range(10,31)),\n",
        "    'max_leaf_nodes': list(range(2, 51)),\n",
        "    'min_samples_split': list(range(1, 5)),\n",
        "    'splitter': ['best', 'random'],\n",
        "    'class_weight': ['balanced', None, {0: 0.1, 1: 0.3, 2: 0.6}]\n",
        "}\n",
        "dt = DecisionTreeClassifier(random_state=22)\n",
        "\n",
        "grid_search_cv = GridSearchCV(dt, params, verbose=1, cv=3, n_jobs=-1)\n",
        "grid_search_cv.fit(train_set, train_label)\n",
        "\n",
        "dt = grid_search_cv.best_estimator_\n",
        "dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN_KZMF20vys",
        "outputId": "a0e3c841-3bf5-4cf9-c655-4a6bd8bdf5be"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Model assessment\n",
        "if oversampling == False:\n",
        "  dt = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
        "                       max_depth=10, max_features=None, max_leaf_nodes=48,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                       random_state=22, splitter='best')\n",
        "else:\n",
        "  dt = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
        "                       max_depth=10, max_features=None, max_leaf_nodes=48,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                       random_state=22, splitter='best')\n",
        "dt.fit(train_set, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "N9CaNzHnwctv",
        "outputId": "79a28030-d678-433b-8ea1-7c6ea03a1617"
      },
      "source": [
        "# Visualize the actual decision tree obtained \n",
        "import pydotplus \n",
        "from sklearn import tree\n",
        "from IPython.display import Image\n",
        "\n",
        "dot_data = tree.export_graphviz(\n",
        "  dt,\n",
        "  out_file=None,\n",
        "  feature_names=list(train_set.columns),\n",
        "  class_names=['low-spending', 'medium-spending', 'high-spending'],\n",
        "  filled=True,\n",
        "  rounded=True\n",
        ")\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fKnoZcfwctv"
      },
      "source": [
        "# Predict using the decision tree\n",
        "train_pred = dt.predict(train_set)\n",
        "test_pred = dt.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "-m3copZfwctv",
        "outputId": "d1634e03-1162-4778-a567-34a6261f8058"
      },
      "source": [
        "compute_scores(dt, train_set, test_set, train_label, train_pred, test_label, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wybWauQtv8Iy"
      },
      "source": [
        "### RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOc24smxwCh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e58975-9575-403f-b71a-8165ce5dba7d"
      },
      "source": [
        "# We define a Random Forest based on the result of a Grid Search\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Model validation\n",
        "param_dist = {\n",
        "  \"max_depth\": list(range(2, 20)),\n",
        "  \"min_samples_split\": list(range(1, 10)),\n",
        "  \"min_samples_leaf\": list(range(1, 10)),\n",
        "  \"bootstrap\": [True, False],\n",
        "  \"criterion\": [\"entropy\", \"gini\"],\n",
        "  \"class_weight\": ['balanced', None, {0: 0.1, 1: 0.3, 2: 0.6}]\n",
        "}\n",
        "clf = RandomForestClassifier(n_estimators=30)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_dist, verbose=1, cv=3, n_jobs=-1)\n",
        "grid_search.fit(train_set, train_label)\n",
        "\n",
        "dt = grid_search.best_estimator_\n",
        "dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wlg1qXRj70H",
        "outputId": "d55f0f7f-8072-4a6b-f5c4-bd5ef55d5b35"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Model assessment\n",
        "if oversampling == False:\n",
        "  dt = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='gini', max_depth=15, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=3, min_samples_split=3,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "else:\n",
        "  dt = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=19, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=3,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "dt.fit(train_set, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohlX3rUWwLa-"
      },
      "source": [
        "# Predict using the decision tree\n",
        "train_pred = dt.predict(train_set)\n",
        "test_pred = dt.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivp71PfAYQKU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "d04ed6f7-1054-49be-c60d-3fefeacc78bd"
      },
      "source": [
        "compute_scores(dt, train_set, test_set, train_label, train_pred, test_label, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au5-ukilYWaA"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqzcZcm1yWrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd606b90-8d97-4d40-a220-b307140f8cee"
      },
      "source": [
        "#import, define and fit the model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB(priors=[0.47017189, 0.38574317, 0.14408493])\n",
        "gnb.fit(train_set, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2LgAALcEHvA"
      },
      "source": [
        "# Predict using the decision tree\n",
        "train_pred = gnb.predict(train_set)\n",
        "test_pred = gnb.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "4e1FEWjHEJ06",
        "outputId": "a782f953-91d5-407e-87d6-3c9a6f559648"
      },
      "source": [
        "compute_scores(gnb, train_set, test_set, train_label, train_pred, test_label, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haa1DpgjldGK"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4ZX4qazEL2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d04c508-110e-4a1f-d517-6b32439e5878"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Model validation\n",
        "params = {\n",
        "    'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,30],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': [ 'ball_tree', 'kd_tree', 'brute' ],\n",
        "    'metric': ['minkowski'],\n",
        "    'p': [1,2]  # 1=manhattan, 2=euclidean\n",
        "}\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "grid_search_cv = GridSearchCV(knn, params, verbose=1, cv=3, n_jobs=-1)\n",
        "grid_search_cv.fit(train_set, train_label)\n",
        "\n",
        "knn = grid_search_cv.best_estimator_\n",
        "knn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdqGl9r8kXro",
        "outputId": "edd60106-87cb-4b87-8c71-60d6f0396972"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Model assessment\n",
        "if oversampling == False:\n",
        "  knn = KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=12, p=1,\n",
        "                     weights='distance')\n",
        "else:\n",
        "  knn = KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=9, p=1,\n",
        "                     weights='distance')\n",
        "knn.fit(train_set, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CqgSUPQmi_q"
      },
      "source": [
        "# Predict using the decision tree\n",
        "train_pred = knn.predict(train_set)\n",
        "test_pred = knn.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "nXYFrrPumejQ",
        "outputId": "32dec7b9-1fd8-471a-ac95-278809c380bc"
      },
      "source": [
        "compute_scores(knn, train_set, test_set, train_label, train_pred, test_label, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7G82kGKlk0H"
      },
      "source": [
        "### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inMP7hf8lkEC",
        "outputId": "8a53e219-59f9-4612-ad58-b96e3f6f234e"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Model validation\n",
        "params = {\n",
        "    'C': np.append( np.arange(0.01,0.9,0.1),0),\n",
        "    'kernel': [ 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale','auto'],\n",
        "    'coef0': np.arange(0.01,0.9,0.1),\n",
        "    'shrinking': [True,False],\n",
        "}\n",
        "svm = SVC(probability=True, random_state=22)\n",
        "\n",
        "grid_search_cv = GridSearchCV(svm, params, verbose=1, cv=3, n_jobs=-1)\n",
        "grid_search_cv.fit(train_set, train_label)\n",
        "\n",
        "svm = grid_search_cv.best_estimator_\n",
        "svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni7bhwfTkpO9",
        "outputId": "4d7c2e63-0664-44a7-f77d-086093356b19"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Model assessment\n",
        "if oversampling == False:\n",
        "  svm = SVC(C=0.81, break_ties=False, cache_size=200, class_weight=None, coef0=0.01,\n",
        "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=22, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "else:\n",
        "  svm = SVC(C=0.81, break_ties=False, cache_size=200, class_weight=None, coef0=0.01,\n",
        "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=22, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "svm.fit(train_set, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOFOH9_BnLu9"
      },
      "source": [
        "# Predict using the decision tree\n",
        "train_pred = svm.predict(train_set)\n",
        "test_pred = svm.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "ocUyHDBfnL-W",
        "outputId": "f3bcfd3d-f6d2-4d22-e0a9-526ac4cd77f1"
      },
      "source": [
        "compute_scores(svm, train_set, test_set, train_label, train_pred, test_label, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjZq6XnGU4nU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb3d29f-9b54-4d3c-db35-0ca04eb5a0c3"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gKRVW9inPiW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "7168ee91-bfec-4e60-da69-12350421fc92"
      },
      "source": [
        "# Roc curve\n",
        "import scikitplot as skplt\n",
        "\n",
        "test_pred_proba = svm.predict_proba(test_set)\n",
        "plot(skplt.metrics.plot_roc_curve(test_label.values, test_pred_proba))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrurl6HjDcGs"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qnn9ko8DdpL",
        "outputId": "b2716c1a-5b02-46e7-eaa2-45ced35699da"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Model creation\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(1, X.shape[1])),\n",
        "  tf.keras.layers.Dense(512, activation='sigmoid'),\n",
        "  tf.keras.layers.Dense(256, activation='sigmoid'),\n",
        "  # tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(3, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adamax',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train!\n",
        "history = model.fit(train_set, to_categorical(train_label.astype('float32')),\n",
        "                    epochs=200,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9FIYznF7Wvmi",
        "outputId": "1b01a55a-dfc5-4047-9ae0-743c79897ca7"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Plot accuracy\n",
        "for todo in ['accuracy', 'loss']:\n",
        "  acc = history.history[todo]\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  val_acc = history.history[f'val_{todo}']\n",
        "  plt.plot(epochs, acc, 'b', label=f'Training {todo}')\n",
        "  plt.plot(epochs, val_acc, 'r', label=f'Validation {todo}')\n",
        "  plt.title(f'Training and validation {todo}')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(todo)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Compute scores\n",
        "train_pred = model.predict_classes(train_set)\n",
        "test_pred = model.predict_classes(test_set)\n",
        "\n",
        "compute_scores(None, train_set, test_set, train_label.values, train_pred, test_label.values, test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}