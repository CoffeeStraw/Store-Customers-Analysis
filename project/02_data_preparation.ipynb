{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "data_preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV2gZTg32bTi"
      },
      "source": [
        "# DATA MINING PROJECT: Analysis of a Supermarketâ€™s Customers\n",
        "## 1.2) Data Preparation\n",
        "### *Antonio Strippoli, Valerio Mariani*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4al2I01D2bTj"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import calendar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from math import log, ceil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('mode.chained_assignment', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd7NhtOe2bTn"
      },
      "source": [
        "def plot(ax, folder=\"cdf_plots\", filename=\"\", figsize=(6.4, 4.8)):\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(*figsize)\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        path = os.path.join(\"..\", \"report\", \"imgs\", folder)\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "        plt.savefig(os.path.join(path, filename))\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzSDEDEN2bTs"
      },
      "source": [
        "### Create a new dataset with a profilation of each customer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX8rfFc_2bTp"
      },
      "source": [
        "# Load the secondary data\n",
        "df = pd.read_csv('customer_supermarket_2.csv', index_col=0, parse_dates=[\"PurchaseDate\"])\n",
        "\n",
        "# Save Qta * Sale in a new column\n",
        "df['Qta_Sale'] = df['Qta'] * df['Sale']\n",
        "\n",
        "# Discretize Sale attribute\n",
        "df['Sale_discr'] = pd.qcut(df['Sale'], 10, duplicates='drop', retbins=False)\n",
        "\n",
        "# Discretize Sale for baskets\n",
        "sale_baskets = df[df['Qta'] > 0][['CustomerID', 'BasketID', 'Qta_Sale']].groupby('BasketID').agg({'Qta_Sale': 'sum', 'CustomerID': 'max'})\n",
        "sale_baskets['Qta_Sale'] = pd.qcut(sale_baskets['Qta_Sale'], 3, duplicates='drop', retbins=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recency\n",
        "recency = lambda g: (df['PurchaseDate'].max() - g['PurchaseDate'].max()).days\n",
        "# Frequency\n",
        "frequency = lambda g: g['BasketID'].nunique()\n",
        "# Total money spent\n",
        "monetary = lambda g: round( sum( g[\"Sale\"]*g[\"Qta\"] ), 2)\n",
        "# Total purchased items\n",
        "tot_items = lambda g: sum( g[\"Qta\"] )\n",
        "# Maximum number of purchased items in a shopping session\n",
        "max_items = lambda g: max( [ sum( g1[1][\"Qta\"] ) for g1 in g.groupby(\"BasketID\") ] )\n",
        "# Medium object in basket\n",
        "mean_items = lambda g: int( np.mean( [ sum( g1[1][\"Qta\"] ) for g1 in g.groupby(\"BasketID\") ] ))\n",
        "# Number of distinct items\n",
        "unique_items = lambda g: g[\"ProdID\"].nunique()\n",
        "# Preferred item\n",
        "preferred_item = lambda g: g.groupby('ProdID').agg({'Qta':'sum'}).idxmax()[0]\n",
        "# Max amount for a basket\n",
        "max_sale = lambda g: round( max( [ sum( g1[1][\"Sale\"]*g1[1][\"Qta\"] ) for g1 in g.groupby(\"BasketID\") ] ), 2)\n",
        "# Medium amount for a basket\n",
        "mean_sale = lambda g: round( np.mean( [ sum( g1[1][\"Sale\"]*g1[1][\"Qta\"] ) for g1 in g.groupby( \"BasketID\" ) ] ), 2)\n",
        "# Medium amount paid for an item\n",
        "mean_item_sale = lambda g: round( np.mean( g[\"Sale\"].unique() ), 2)\n",
        "# Entropies\n",
        "def entropy_products(g):\n",
        "    l = g[[\"ProdID\", 'Qta']].groupby('ProdID').agg('sum')\n",
        "    m = l.values.sum()\n",
        "    e = -sum( [ (mi/m)*log((mi/m), 2) for mi in l.values.flatten() ] )\n",
        "    return round(e, 2)\n",
        "def entropy_sale(g):\n",
        "    l = g['Sale_discr'].value_counts()\n",
        "    l = l[l > 0]\n",
        "    m = l.values.sum()\n",
        "    e = -sum( [ (mi/m)*log((mi/m), 2) for mi in l.values.flatten() ] )\n",
        "    return round(e, 2)\n",
        "def entropy_baskets(customer_id, g):\n",
        "    l = sale_baskets[sale_baskets['CustomerID'] == customer_id]['Qta_Sale'].value_counts()\n",
        "    l = l[l > 0]\n",
        "    m = l.values.sum()\n",
        "    e = -sum( [ (mi/m)*log((mi/m), 2) for mi in l.values.flatten() ] )\n",
        "    return round(e, 2)\n",
        "def entropy_intervals(g):\n",
        "    # Get unique dates (without considering time)\n",
        "    dates = g['PurchaseDate']\n",
        "    dates = pd.DataFrame(dates.dt.normalize().unique(), columns=[\"date\"])\n",
        "\n",
        "    # If we have only one record, duplicate it to be able to compute a fake interval\n",
        "    if len(dates) == 1:\n",
        "        dates = dates.append(pd.Series(dates.iloc[0]))\n",
        "        dates.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    dates['date2'] = dates['date'].shift(1)\n",
        "    dates.drop(0, inplace=True)\n",
        "    l = (dates['date'] - dates['date2']).dt.days\n",
        "    # Do binning of values by weeks and calculate entropies\n",
        "    l = np.ceil(l / 7).value_counts()\n",
        "    m = l.values.sum()\n",
        "    e = -sum( [ (mi/m)*log((mi/m), 2) for mi in l.values.flatten() ] )\n",
        "    return round(e, 2)\n",
        "# Purchasing Frequency\n",
        "purchasing_freq = lambda g: round((g['PurchaseDate'].max() - g['PurchaseDate'].min()).days / g['BasketID'].nunique(), 2)\n",
        "# Weekday preference\n",
        "weekday_pref = lambda g: int(pd.Series(g['PurchaseDate'].unique()).apply(lambda x: x.weekday()).mean())\n",
        "# Number of week of the month preference\n",
        "weekmonth_pref = lambda g: int(pd.Series(g['PurchaseDate'].unique()).apply( lambda x: int(ceil(x.day/7.0)) ).mean())\n",
        "# Main country\n",
        "main_country = lambda g: g[['BasketID','CustomerCountry']].groupby('CustomerCountry').nunique().idxmax()[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "MoApBoDX2bTy"
      },
      "source": [
        "groups = df[df[\"Qta\"]>0].groupby(\"CustomerID\")\n",
        "cdf = pd.DataFrame(data=np.array( [\n",
        "    [\n",
        "    group[0],\n",
        "    recency(group[1]),\n",
        "    frequency(group[1]),\n",
        "    monetary(group[1]),\n",
        "    tot_items(group[1]),\n",
        "    max_items(group[1]),\n",
        "    mean_items(group[1]),\n",
        "    unique_items(group[1]),\n",
        "    max_sale(group[1]),\n",
        "    mean_sale(group[1]),\n",
        "    mean_item_sale(group[1]),\n",
        "    entropy_products(group[1]),\n",
        "    entropy_sale(group[1]),\n",
        "    entropy_baskets(group[0], group[1]),\n",
        "    entropy_intervals(group[1]),\n",
        "    purchasing_freq(group[1]),\n",
        "    weekday_pref(group[1]),\n",
        "    weekmonth_pref(group[1]),\n",
        "    preferred_item(group[1]),\n",
        "    main_country(group[1])\n",
        "    ] for group in groups\n",
        "] ), columns=[\"CustomerID\",\"Recency\",\"Frequency\",\"Monetary\",\"TotItems\",\"MaxItems\",\"MeanBasketItems\",\"UniqueItems\",\"MaxSale\",\"MeanBasketSale\",\"MeanItemSale\",\"E-Prods\",\"E-Sale\",\"E-Baskets\",\"E-Intervals\",\"PurchasingFreq\",\"WeekDayPref\",\"WeekMonthPref\",\"ItemPref\",\"MainCountry\"] )\n",
        "cdf.set_index('CustomerID', inplace=True)\n",
        "\n",
        "# Workaround for Pandas' bug (not able to convert to correct dtypes)\n",
        "# cdf.convert_dtypes()\n",
        "cdf.to_csv(\"customer_profilation.csv\")\n",
        "cdf = pd.read_csv(\"customer_profilation.csv\", index_col=0)\n",
        "\n",
        "# calculate percentage of returned item for customer\n",
        "groups = df[ (df[\"Qta\"]<0) & ~(df[\"ProdID\"].isin(['M', 'D', 'BANK CHARGES'])) ][['CustomerID','Qta']].groupby(\"CustomerID\").agg('sum')\n",
        "cdf.insert(7, 'PReturn', pd.Series(\n",
        "    [ round(-groups.loc[i]['Qta']/cdf.loc[i]['TotItems']*100, 2) if i in groups.index else 0 for i in cdf.index ],\n",
        "    dtype='float64',\n",
        "    index=cdf.index\n",
        "))\n",
        "\n",
        "print(\"N. ENTRIES:\", len(cdf))\n",
        "cdf.to_csv(\"customer_profilation.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU5dfb7T2bT1"
      },
      "source": [
        "### Data Quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UQSRGcD2bT2",
        "outputId": "1d2645b7-4058-4472-9d38-c38094eb81a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "# Load new created dataset do some final polishing\n",
        "cdf = pd.read_csv(\"customer_profilation.csv\", index_col=0)\n",
        "\n",
        "cdf.info()\n",
        "cdf.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhxx2cUg2bT7"
      },
      "source": [
        "# Outliers in TotItems (users who purchased an abnormal number of items)\n",
        "cdf_totitems = cdf['TotItems']\n",
        "plot(cdf_totitems.plot.box(), figsize=(2, 4.8), folder=\"cdf_outliers\", filename=\"TotItems_BP\")\n",
        "plot(sn.distplot(cdf_totitems[cdf_totitems < 25000], bins=100), folder=\"cdf_outliers\", filename=\"TotItems_HIST\")\n",
        "\n",
        "# Search for a threshold\n",
        "plot(cdf_totitems[cdf_totitems < 100000].plot.box(), figsize=(2, 4.8))\n",
        "plot(cdf_totitems[cdf_totitems < 70000].plot.box(), figsize=(2, 4.8))\n",
        "\n",
        "cdf = cdf[cdf_totitems < 70000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vdxOYT2bT-"
      },
      "source": [
        "# Outliers in Monetary (users who spent way too much money)\n",
        "cdf_monetary = cdf['Monetary']\n",
        "plot(cdf_monetary.plot.box(), figsize=(2, 4.8), folder=\"cdf_outliers\", filename=\"Monetary_BP\")\n",
        "plot(sn.distplot(cdf_monetary[cdf_monetary < 25000], bins=100), folder=\"cdf_outliers\", filename=\"Monetary_HIST\")\n",
        "\n",
        "# Search for a threshold\n",
        "plot(cdf_monetary[cdf_monetary < 80000].plot.box(), figsize=(2, 4.8))\n",
        "\n",
        "cdf = cdf[cdf_monetary < 80000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"N. ENTRIES:\", len(cdf))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKoNjY4s2bUD"
      },
      "source": [
        "cdf.to_csv(\"customer_profilation.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDt4hj3Z2bUG"
      },
      "source": [
        "### Distribution & Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7xIMNh72bUG"
      },
      "source": [
        "# Load new dataset and start performing some analysis\n",
        "cdf = pd.read_csv(\"customer_profilation.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LXBWdUI2bUI",
        "outputId": "65d39310-a78b-44df-fc5b-d74a22167f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Pandas' scatter matrix\n",
        "plot(pd.plotting.scatter_matrix(cdf), figsize=(20,20), filename=\"ScatterMatrix\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwbnmc7t2bUN",
        "outputId": "033b4808-81a1-4695-da18-c162d0c6c025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Distribution of numerical attributes with histograms\n",
        "plot(cdf.hist(bins=50), figsize=(10,10), filename=\"Histograms\")\n",
        "\n",
        "# Distribution of numerical attributes with box-plots\n",
        "plot(cdf.plot.box(), filename=\"Box_Plots\")\n",
        "\n",
        "# Pairwise correlations with heatmap on correlation matrix\n",
        "plot(sn.heatmap(round(cdf.corr(), 2), cmap='coolwarm', annot=True), figsize=(10,10), filename=\"HeatMap_Correlations\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve highest correlations\n",
        "tmp = round(cdf.corr(), 2).abs().unstack()\n",
        "tmp = tmp[tmp != 1]\n",
        "tmp.sort_values(ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze PurchasingFreq attribute\n",
        "print(cdf['PurchasingFreq'].describe())\n",
        "plot(cdf['PurchasingFreq'].hist(bins=100))\n",
        "plot(cdf['PurchasingFreq'].plot.box())\n",
        "\n",
        "plot(cdf.plot.scatter(x='PurchasingFreq', y='Frequency', c='PurchasingFreq', cmap='copper', colorbar=False, sharex=False), filename=\"Frequency_PurchasingFreq\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGZrft5p5YG1",
        "outputId": "5a4bcc7e-1cf6-4f0b-febb-6712079b8e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Study and save some particular distributions and correlations\n",
        "plot(sn.distplot(cdf['Recency'], bins=100), filename=\"Recency_HIST\")\n",
        "plot(cdf['WeekDayPref'].value_counts().sort_index().rename(lambda i: calendar.day_name[i]).plot.bar(), filename=\"WeekDayPref_HIST\")\n",
        "plot(cdf['WeekMonthPref'].value_counts().sort_index().plot.bar(), filename=\"WeekMonthPref_HIST\")\n",
        "plot(sn.distplot(cdf['PReturn'], bins=100), filename=\"PReturn_HIST\")\n",
        "plot(sn.distplot(cdf['E-Prods'], bins=100), filename=\"EProds_HIST\")\n",
        "plot(sn.distplot(cdf['E-Sale'], bins=100), filename=\"ESale_HIST\")\n",
        "plot(sn.distplot(cdf['E-Baskets'], bins=100), filename=\"EBaskets_HIST\")\n",
        "plot(sn.distplot(cdf['E-Intervals'], bins=100), filename=\"EIntervals_HIST\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdO-VdY18RWU",
        "outputId": "f44fc7ea-0870-4d98-c7de-56b5c0bb152e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "# Scatter plot to show correlation of the 2 entropies\n",
        "plot(cdf.plot.scatter('E-Prods', 'E-Sale', c='Recency', colormap='hot', sharex=False), figsize=(8,6), filename=\"Entropies\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVQ4NlO-94J1",
        "outputId": "1e46fe2e-31f2-4674-b0d9-440e6a1bc93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "# 3D Scatter plot to show correlations between entropies, frequency and unique items\n",
        "fig = plt.figure(figsize = (10, 7))\n",
        "ax = plt.axes(projection =\"3d\")\n",
        "\n",
        "p = ax.scatter3D(cdf['E-Prods'], cdf['E-Sale'], cdf['UniqueItems'], c=cdf['Recency'], cmap='hot')\n",
        "cbar = fig.colorbar(p)\n",
        "ax.set_xlabel('E-Prods')\n",
        "ax.set_ylabel('E-Sale')\n",
        "ax.set_zlabel('UniqueItems')\n",
        "cbar.set_label('Recency')\n",
        "\n",
        "plot(ax, figsize=(8,6), filename=\"Entropies_3D\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdYXfnMJ_hdg",
        "outputId": "6bae7c28-319b-4c57-f183-b4cddc583e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "# Scatter plot to show correlation of PReturn and Frequency\n",
        "plot(cdf.plot.scatter('PReturn', 'Frequency', c='Recency', colormap='plasma', sharex=False), figsize=(8,6), filename=\"PReturn_Frequency\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check meanitemsale (not interesting)\n",
        "plot(cdf['MeanItemSale'].hist(bins=100))\n",
        "plot(cdf['MeanItemSale'].plot.box())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check frequency (not interesting)\n",
        "print(cdf['Frequency'].describe())\n",
        "print(cdf['Frequency'].quantile([.80, .85, .90, .95]))\n",
        "plot(cdf['Frequency'].hist(bins=100))\n",
        "plot(cdf['Frequency'].plot.box())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cdf[(cdf['Monetary'] < 20000) & (cdf['TotItems'] < 20000)].plot.scatter(x='Monetary', y='TotItems')"
      ]
    }
  ]
}