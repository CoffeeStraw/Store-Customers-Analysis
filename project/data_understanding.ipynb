{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DATA MINING PROJECT: Analysis of a Supermarketâ€™s Customers\n",
    "## 1.1) Data Understanding: Semantics & Quality\n",
    "### *Antonio Strippoli, Valerio Mariani*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from scipy import stats\n",
    "from math import log, ceil\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ax, filename=\"\", figsize=(6.4, 4.8)):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(*figsize)\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(f\"../report/imgs/{filename}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the given file\n",
    "df = pd.read_csv('customer_supermarket.csv', sep='\\t', index_col=0, parse_dates=[\"BasketDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints data's samples and informations,\n",
    "# including the number of not null values for each columns\n",
    "df.info()\n",
    "print(\"\")\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Data Semantics\n",
    "Perform some variable wise checks to understand the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE: Check if basket starting with 'C' all have quantity less than 0\n",
    "# Results: only basket starting with 'C' have quantity less than 0\n",
    "tmp = df[ (df[\"BasketID\"].str.contains('C')) & (df[\"Qta\"] > 0) ]\n",
    "print(\"N. BasketID STARTING WITH 'C' AND WITH Qta > 0:\", len(tmp))\n",
    "\n",
    "tmp = df[ (df[\"Qta\"] < 0) & ~(df[\"BasketID\"].str.contains('C')) ]\n",
    "tmp.dropna(subset=['CustomerID'], inplace=True)\n",
    "print(\"N. BasketID NOT STARTING WITH 'C' AND WITH Qta < 0:\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if we have the same product inside the same basket\n",
    "# Result: two cases, same price, different price\n",
    "def check_duplicated_prods(x):\n",
    "    if len(x) > 1 and x[\"Sale\"].nunique() == 1:\n",
    "        return x\n",
    "    return None\n",
    "\n",
    "tmp = df.groupby(['BasketID','BasketDate','ProdID']).apply(check_duplicated_prods).dropna()\n",
    "\n",
    "print(\"SAMPLE OF BASKET WITH INCONSISTENT Qta:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if with same BasketID we have different datetimes\n",
    "# Results: change BasketDate to PurchaseDate\n",
    "tmp = df.groupby([\"BasketID\"]).nunique()[\"BasketDate\"].eq(1)\n",
    "tmp = tmp[tmp == False]\n",
    "print(\"INCONSISTENT BasketDates:\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if two customers happen to have the same BasketID\n",
    "# Result: after removing duplicates no other wrong value found\n",
    "tmp = df.groupby([\"BasketID\", \"CustomerID\"]).ngroups\n",
    "print(\"N. BasketID-CustomerID COUPLES:\", tmp)\n",
    "\n",
    "tmp = df[\"BasketID\"].nunique()\n",
    "print(\"N. BasketID:\", tmp)\n",
    "\n",
    "tmp = df.dropna(subset=['CustomerID'])\n",
    "tmp = tmp.groupby([\"BasketID\"]).nunique()[\"CustomerID\"].eq(1)\n",
    "tmp = tmp[tmp == False].index\n",
    "print(\"INCONSITENT BasketID-CustomerID (after NaN removal):\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if discount are always alone in the basket\n",
    "# Result: Almost always, only one time we have it together with Manual\n",
    "tmp = df[\n",
    "    df[\"BasketID\"].isin(\n",
    "        df[df['ProdID'] == \"D\"][\"BasketID\"]\n",
    ")]\n",
    "tmp = tmp[tmp[\"ProdID\"] != \"D\"]\n",
    "print(\"PRODUCTS IN THE SAME BASKET WITH DISCOUNT:\\n\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if baskets only are numerical with an optional starting 'C' character\n",
    "# Result: We found baskets starting with 'A', which however will be removed since they have sales less than 0\n",
    "tmp = df[~df['BasketID'].str.contains('C')][df['BasketID'].str.contains('[A-Za-z]')][\"BasketID\"].unique()\n",
    "print(\"STRANGE BASKETS:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for strange ProductID (nor alphanumerical code only)\n",
    "# Result: A lot of products contains characters, we get to know about discounts and bank charges\n",
    "tmp = df[df['ProdID'].str.contains('[A-Za-z]')][\"ProdID\"].unique()\n",
    "print(\"STRANGE ProductID:\\n\", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-uppercase descriptions\n",
    "# Result: we get to know about descriptions being inconsistent and some strange descriptions\n",
    "tmp = df['ProdDescr'].isna().sum()\n",
    "print(\"N. NaN ProdDescr:\", tmp)\n",
    "\n",
    "tmp = df.dropna(subset=['ProdDescr'])\n",
    "tmp = tmp[tmp['ProdDescr'].str.contains('[a-z]')][\"ProdDescr\"].unique()\n",
    "print(\"INCONSISTENT ProdDescr:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check list of countries\n",
    "# Result: (Get to know about hidden null-values: 'Unspecified')\n",
    "tmp = list(sorted(list(df[\"CustomerCountry\"].unique())))\n",
    "print(\"COUNTRIES:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for strange qta values\n",
    "# Result: Get to know about negative values and outliers\n",
    "tmp = df['Qta'].describe()\n",
    "print(\"Qta Descr:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomerCountry seems like the country where the user registered... is that true?\n",
    "# Result: no, since some IDs have different countries. Some customers may have changed their nationality.\n",
    "# We will take this into account when we will create the customer profilation dataset.\n",
    "tmp = df.groupby([\"CustomerID\"]).nunique()[\"CustomerCountry\"].eq(1)\n",
    "tmp = list(tmp[tmp == False].index)\n",
    "print(\"INCONSISTENT CustomerCountry:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all ProdID have one ProdDescr?\n",
    "# Result: No, some descriptions are more verbose, we will take those\n",
    "tmp = df.groupby([\"ProdID\"]).nunique()[\"ProdDescr\"].eq(1)\n",
    "tmp = tmp[tmp == False].index\n",
    "print(\"N. INCONSISTENT ProdDescr:\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have sales with more than 3 digit places?\n",
    "# Result: Yes, we will round them\n",
    "tmp = df[\"Sale\"].astype(str).str.contains(r\",\\d{3,}\")\n",
    "tmp = tmp[tmp == True].index\n",
    "tmp = df.loc[tmp]\n",
    "print(\"INCONSISTENT Sale:\")\n",
    "tmp"
   ]
  },
  {
   "source": [
    "## Data Quality\n",
    "Clean up the datas by correcting semantical errors, removing outliers and other mixed fixes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts sale to float, accomodating the csv format\n",
    "df[\"Sale\"] = df[\"Sale\"].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Remove unidentified customers and converts CustomerID to int\n",
    "df.dropna(subset=['CustomerID'], inplace=True)\n",
    "df[\"CustomerID\"] = df[\"CustomerID\"].astype(int)\n",
    "\n",
    "# Put all characters in uppercase and remove extra whitespaces for products' description\n",
    "df[\"ProdDescr\"] = df[\"ProdDescr\"].str.upper().str.strip()\n",
    "\n",
    "# Put all characters in uppercase for product ids\n",
    "df[\"ProdID\"] = df[\"ProdID\"].str.upper()\n",
    "\n",
    "# Remove purchases with prices less than or equal to zero, together with some outliers that costs less than 0.01\n",
    "# We remove them since they're few (4)\n",
    "df = df[df[\"Sale\"] >= 0.01]\n",
    "\n",
    "# Remove C from basketIDs, since it is pointless (we already have negative quantities to identify those)\n",
    "# NOTE: We also previously dropped baskets starting with 'A', which had negative sale\n",
    "df[\"BasketID\"] = df[\"BasketID\"].str.replace('C', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform descriptions of same productIDs by taking the longest (more informations)\n",
    "tmp = df.groupby([\"ProdID\"]).nunique()[\"ProdDescr\"].eq(1)\n",
    "tmp = tmp[tmp == False].index\n",
    "new_prod_descr = df[df[\"ProdID\"].isin(tmp)].groupby(\"ProdID\").agg({'ProdDescr': 'max'})\n",
    "\n",
    "def uniform_descr(x):\n",
    "    if x.loc[\"ProdID\"] in new_prod_descr.index:\n",
    "        descr = new_prod_descr.loc[x.loc[\"ProdID\"]][\"ProdDescr\"]\n",
    "        x.loc[\"ProdDescr\"] = descr\n",
    "    return x\n",
    "\n",
    "df[[\"ProdID\", \"ProdDescr\"]] = df[[\"ProdID\", \"ProdDescr\"]].apply(uniform_descr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put multiple products in the same basket as a single product\n",
    "df = df.groupby(['BasketID','ProdID']).agg({\n",
    "    'BasketDate': 'min',\n",
    "    'Qta': 'sum',\n",
    "    'Sale': 'mean',\n",
    "    'CustomerID': 'min',\n",
    "    'CustomerCountry': 'min',\n",
    "    'ProdDescr': 'min'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows corresponding to returns without relative purchase (inconsistent data)\n",
    "invalid_indexes = []\n",
    "def get_invalid_indexes(x):\n",
    "    x = x.sort_values(by='BasketDate')\n",
    "    s = 0\n",
    "    for i, qta in enumerate(x['Qta']):\n",
    "        if (s := s + qta) < 0:\n",
    "            invalid_indexes.append(x.iloc[i].name)\n",
    "            s = 0\n",
    "\n",
    "df[ ~df[\"ProdID\"].isin(['M', 'D', 'BANK CHARGES']) ].groupby(['CustomerID', 'ProdID']).apply(get_invalid_indexes)\n",
    "df.drop(invalid_indexes, inplace=True)"
   ]
  },
  {
   "source": [
    "### OUTLIERS REMOVAL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "def iqr_non_outliers(s: pd.Series):\n",
    "    \"\"\"Returns a true-list of the outliers in a column\n",
    "    of the DataFrame, based on the quantiles\"\"\"\n",
    "    Q1 = s.quantile(0.25)\n",
    "    Q3 = s.quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    trueList = (s < (Q1 - 1.5 * IQR)) | (s > (Q3 + 1.5 * IQR))\n",
    "    return trueList"
   ]
  },
  {
   "source": [
    "### Outliers in ATTRIBUTES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in ATTRIBUTES from QTA\n",
    "df_qta = df[\"Qta\"]\n",
    "\n",
    "plot(df_qta.plot.box(), figsize=(2, 4.8), filename=\"Outliers_Articles_Qta_BP\")\n",
    "plot(df_qta[abs(df_qta) < 100].hist(bins=100), filename=\"Outliers_Articles_Qta_HIST\")\n",
    "\n",
    "# Would IQR be effective?\n",
    "# Result: no, since we think that most of the customers are wholesalers and it would drop too many entries\n",
    "iqr_outliers = df_qta[~iqr_non_outliers(df_qta)]\n",
    "print(\"QTA - IQR RESULTS:\\n\", iqr_outliers.describe())\n",
    "print(\"MIN Qta Positives:\", iqr_outliers[iqr_outliers > 0].min())\n",
    "print(\"MAX Qta Negatives:\", iqr_outliers[iqr_outliers < 0].max())\n",
    "\n",
    "# Search for a threshold\n",
    "plot(df_qta[abs(df_qta) < 10000].plot.box(), figsize=(2, 4.8))\n",
    "plot(df_qta[(df_qta < 3500) & (df_qta > -2000)].plot.box(), figsize=(2, 4.8))\n",
    "\n",
    "# One last check: how are those outliers distributed among the users?\n",
    "outliers_i = df_qta[(df_qta > 3500) | (df_qta < -2000)].index\n",
    "outliers = df.loc[outliers_i]\n",
    "print(\"QTA OUTLIERS (with threshold of 3500):\")\n",
    "print(outliers[\"Qta\"].describe())\n",
    "print(outliers[\"CustomerID\"].nunique())\n",
    "\n",
    "# Values come from different users, we cannot just drop the customers, must instead drop single tuples\n",
    "df.drop(outliers_i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in ATTRIBUTES from SALE\n",
    "df_sale = df['Sale']\n",
    "\n",
    "plot(df_sale.plot.box(), figsize=(2, 4.8), filename=\"Outliers_Articles_Sale_BP\")\n",
    "plot(df_sale[df_sale < 50].hist(bins=100), filename=\"Outliers_Articles_Sale_HIST\")\n",
    "\n",
    "# Search for a threshold and remove based on that\n",
    "plot(df_sale[df_sale < 5000].plot.box(), figsize=(2, 4.8))\n",
    "plot(df_sale[df_sale < 2200].plot.box(), figsize=(2, 4.8))\n",
    "df = df[df_sale < 2200]"
   ]
  },
  {
   "source": [
    "### Outliers in BASKETS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in BASKETS from QTA\n",
    "df_basket_qta = df[[\"BasketID\", \"Qta\"]].groupby(\"BasketID\").agg('sum')[\"Qta\"]\n",
    "\n",
    "plot(df_basket_qta.plot.box(), figsize=(2, 4.8), filename=\"Outliers_Basket_Sale_BP\")\n",
    "plot(df_basket_qta[abs(df_basket_qta) < 2000].hist(bins=100), filename=\"Outliers_Basket_Sale_HIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove in BASKETS from SALE\n",
    "df_basket_cost = df[['BasketID', 'Qta', 'Sale']]\n",
    "df_basket_cost['Cost'] = df_basket_cost['Qta'] * df_basket_cost['Sale']\n",
    "df_basket_cost = df_basket_cost[[\"BasketID\", \"Cost\"]].groupby(\"BasketID\").agg('sum')[\"Cost\"]\n",
    "\n",
    "plot(df_basket_cost.plot.box(), figsize=(2, 4.8), filename=\"Outliers_Basket_Sale_BP\")\n",
    "plot(df_basket_cost[(df_basket_cost > -2000) & (df_basket_cost < 6000)].hist(bins=100), filename=\"Outliers_Basket_Sale_HIST\")\n",
    "\n",
    "# Check if IQR \n",
    "iqr_outliers = df_basket_cost[~iqr_non_outliers(df_basket_cost)]\n",
    "print(\"BASKETID - IQR RESULTS:\\n\", iqr_outliers.describe())\n",
    "print(\"MIN BASKETID-COST Postives:\", iqr_outliers[iqr_outliers > 0].min())\n",
    "print(\"MAX BASKETID-COST Negatives:\", iqr_outliers[iqr_outliers < 0].max())\n",
    "\n",
    "# Search for a threshold\n",
    "plot(df_basket_cost[(df_basket_cost > -8000) & (df_basket_cost < 30000)].plot.box(), figsize=(2, 4.8), filename=\"Outliers_Basket_Sale_BP\")\n",
    "\n",
    "# One last check: how are those outliers distributed among the users?\n",
    "outliers = df_basket_cost[(df_basket_cost <= -8000) | (df_basket_cost >= 30000)].index\n",
    "customer_outliers = df[df['BasketID'].isin(outliers)]['CustomerID'].unique()\n",
    "print(\"BASKETID OUTLIERS (WITH THRESHOLD)\")\n",
    "print(\"Baskets outliers:\", len(outliers))\n",
    "print(\"Customers having those baskets:\", len(customer_outliers))\n",
    "\n",
    "# Values come from different users, we cannot just drop the customers, must instead drop single tuples\n",
    "df = df[~df[\"BasketID\"].isin(outliers)]"
   ]
  },
  {
   "source": [
    "### Outliers in Customers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove in CUSTOMERID from Total Items Purchased\n",
    "df_customer_qta = df[['CustomerID', 'Qta']].groupby('CustomerID').agg('sum')\n",
    "\n",
    "plot(df_customer_qta.plot.box(), figsize=(2, 4.8), filename=\"Outliers_Customer_Qta_BP\")\n",
    "plot(df_customer_qta[df_customer_qta < 25000].hist(bins=100), filename=\"Outliers_Customer_Qta_HIST\")\n",
    "\n",
    "# Search a threshold\n",
    "plot(df_customer_qta[df_customer_qta < 100000].plot.box(), figsize=(2, 4.8), filename=\"Outliers_Customer_Qta_BP\")\n",
    "plot(df_customer_qta[df_customer_qta < 70000].plot.box(), figsize=(2, 4.8), filename=\"Outliers_Customer_Qta_BP\")\n",
    "\n",
    "non_outliers = df_customer_qta[df_customer_qta < 70000].dropna().index\n",
    "df = df[df['CustomerID'].isin(non_outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove in CUSTOMERID from Profit\n",
    "df_customer_sale = pd.Series([round( sum( g[1][\"Sale\"]*g[1][\"Qta\"] ), 2) for g in df.groupby('CustomerID')], index=[g[0] for g in df.groupby('CustomerID')], name=\"Profit\")\n",
    "\n",
    "plot(df_customer_sale.plot.box(), figsize=(2, 4.8), filename=\"Outliers_Customer_Sale_BP\")\n",
    "plot(df_customer_sale[df_customer_sale < 25000].hist(bins=100), filename=\"Outliers_Basket_Sale_HIST\")\n",
    "\n",
    "# Search a threshold\n",
    "plot(df_customer_sale[df_customer_sale < 80000].plot.box(), figsize=(2, 4.8), filename=\"Outliers_Customer_Sale_BP\")\n",
    "\n",
    "non_outliers = df_customer_sale[df_customer_sale < 80000].dropna().index\n",
    "df = df[df['CustomerID'].isin(non_outliers)]"
   ]
  },
  {
   "source": [
    "### Minor final changes and save the dataset as a secondary data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns with names that could mislead\n",
    "df.rename(columns={'BasketDate': 'PurchaseDate'}, inplace=True)\n",
    "\n",
    "# Swap columns\n",
    "df = df[[\"BasketID\", \"ProdID\", \"ProdDescr\", \"Sale\", \"Qta\", \"PurchaseDate\", \"CustomerID\",\"CustomerCountry\"]]\n",
    "\n",
    "# Sort by date the dataset and reset indexes\n",
    "df.sort_values(\"PurchaseDate\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the pre-processed dataset\n",
    "df.to_csv(\"customer_supermarket_2.csv\")"
   ]
  }
 ]
}