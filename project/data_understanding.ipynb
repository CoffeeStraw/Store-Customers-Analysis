{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DATA MINING PROJECT: Analysis of a Supermarketâ€™s Customers\n",
    "## 1.1) Data Understanding: Semantics & Quality\n",
    "### *Antonio Strippoli, Valerio Mariani*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ax, folder=\"df_outliers\", filename=\"\", figsize=(6.4, 4.8)):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(*figsize)\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        path = os.path.join(\"..\", \"report\", \"imgs\", folder)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        plt.savefig(os.path.join(path, filename))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the given file\n",
    "df = pd.read_csv('customer_supermarket.csv', sep='\\t', index_col=0, parse_dates=[\"BasketDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints data's samples and informations,\n",
    "# including the number of not null values for each columns\n",
    "df.info()\n",
    "print(\"\")\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Data Semantics\n",
    "Perform some variable wise checks to understand the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if basket starting with 'C' all have quantity less than 0\n",
    "# Results: only basket starting with 'C' have quantity less than 0\n",
    "tmp = df[df[\"BasketID\"].str.contains('C')]\n",
    "print(\"N. BasketID STARTING WITH 'C'\", len(tmp))\n",
    "\n",
    "tmp = df[ (df[\"BasketID\"].str.contains('C')) & (df[\"Qta\"] > 0) ]\n",
    "print(\"N. BasketID STARTING WITH 'C' AND WITH Qta > 0:\", len(tmp))\n",
    "\n",
    "tmp = df[ (df[\"Qta\"] < 0) & ~(df[\"BasketID\"].str.contains('C')) ]\n",
    "tmp.dropna(subset=['CustomerID'], inplace=True)\n",
    "print(\"N. BasketID NOT STARTING WITH 'C' AND WITH Qta < 0:\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Understand how 'C' works\n",
    "# Result: it is not easy to retrieve the original order... We will have to make this for each (CustomerID, ProductID)\n",
    "attributes = ['CustomerID', 'ProdID', 'Sale', 'Qta']\n",
    "cancelled = df[df[\"BasketID\"].str.contains('C')].groupby('BasketID')\n",
    "for i, c in enumerate(cancelled):\n",
    "    c = c[1][attributes].sort_values(attributes)\n",
    "    purchases = df[(df['CustomerID'] == c.iloc[0]['CustomerID']) & ~(df[\"BasketID\"].str.contains('C'))]\n",
    "    for p in purchases.groupby('BasketID'):\n",
    "        p = p[1][attributes].sort_values(attributes)\n",
    "        if np.array_equal(c.values,p.values):\n",
    "            print(c)\n",
    "            print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if we have the same product inside the same basket\n",
    "# Result: two cases, same price, different price\n",
    "def check_duplicated_prods(x):\n",
    "    if len(x) > 1 and x[\"Sale\"].nunique() == 1:\n",
    "        return x\n",
    "    return None\n",
    "\n",
    "tmp = df.groupby(['BasketID','BasketDate','ProdID']).apply(check_duplicated_prods).dropna()\n",
    "\n",
    "print(\"SAMPLE OF BASKET WITH INCONSISTENT Qta:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if with same BasketID we have different datetimes\n",
    "# Results: change BasketDate to PurchaseDate\n",
    "tmp = df.groupby([\"BasketID\"]).nunique()[\"BasketDate\"].eq(1)\n",
    "tmp = tmp[tmp == False]\n",
    "print(\"INCONSISTENT BasketDates:\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if two customers happen to have the same BasketID\n",
    "# Result: after removing duplicates no other wrong value found\n",
    "tmp = df.groupby([\"BasketID\", \"CustomerID\"]).ngroups\n",
    "print(\"N. BasketID-CustomerID COUPLES:\", tmp)\n",
    "\n",
    "tmp = df[\"BasketID\"].nunique()\n",
    "print(\"N. BasketID:\", tmp)\n",
    "\n",
    "tmp = df.dropna(subset=['CustomerID'])\n",
    "tmp = tmp.groupby([\"BasketID\"]).nunique()[\"CustomerID\"].eq(1)\n",
    "tmp = tmp[tmp == False].index\n",
    "print(\"INCONSITENT BasketID-CustomerID (after NaN removal):\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if discount are always alone in the basket\n",
    "# Result: Almost always, only one time we have it together with Manual\n",
    "tmp = df[\n",
    "    df[\"BasketID\"].isin(\n",
    "        df[df['ProdID'] == \"D\"][\"BasketID\"]\n",
    ")]\n",
    "tmp = tmp[tmp[\"ProdID\"] != \"D\"]\n",
    "print(\"PRODUCTS IN THE SAME BASKET WITH DISCOUNT:\\n\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if baskets only are numerical with an optional starting 'C' character\n",
    "# Result: We found baskets starting with 'A', which however will be removed since they have sales less than 0\n",
    "tmp = df[~df['BasketID'].str.contains('C')][df['BasketID'].str.contains('[A-Za-z]')][\"BasketID\"].unique()\n",
    "print(\"STRANGE BASKETS:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for strange ProductID (nor alphanumerical code only)\n",
    "# Result: A lot of products contains characters, we get to know about discounts and bank charges\n",
    "tmp = df[df['ProdID'].str.contains('[A-Za-z]')]\n",
    "tmp = tmp[~tmp['ProdID'].str.contains('[0-9]')][['ProdID', 'ProdDescr']].drop_duplicates()\n",
    "print(\"STRANGE ProductID:\")\n",
    "for e in tmp.index:\n",
    "    print(tmp.loc[e]['ProdID'], tmp.loc[e]['ProdDescr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-uppercase descriptions\n",
    "# Result: we get to know about descriptions being inconsistent and some strange descriptions, which we will remove\n",
    "# We decided to not include discounts, gift cards, manuals and bank charges\n",
    "tmp = df['ProdDescr'].isna().sum()\n",
    "print(\"N. NaN ProdDescr:\", tmp)\n",
    "\n",
    "tmp = df.dropna(subset=['ProdDescr'])\n",
    "tmp = tmp[tmp['ProdDescr'].str.contains('[a-z]')][\"ProdDescr\"].unique()\n",
    "print(\"INCONSISTENT ProdDescr:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check list of countries\n",
    "# Result: (Get to know about hidden null-values: 'Unspecified')\n",
    "tmp = list(sorted(list(df[\"CustomerCountry\"].unique())))\n",
    "print(\"COUNTRIES:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for strange qta values\n",
    "# Result: Get to know about negative values and outliers\n",
    "tmp = df['Qta'].describe()\n",
    "print(\"Qta Descr:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomerCountry seems like the country where the user registered... is that true?\n",
    "# Result: no, since some IDs have different countries. Some customers may have changed their nationality.\n",
    "# We will take this into account when we will create the customer profilation dataset.\n",
    "tmp = df.groupby([\"CustomerID\"]).nunique()[\"CustomerCountry\"].eq(1)\n",
    "tmp = list(tmp[tmp == False].index)\n",
    "print(\"INCONSISTENT CustomerCountry:\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all ProdID have one ProdDescr?\n",
    "# Result: No, some descriptions are more verbose, we will take those\n",
    "tmp = df.groupby([\"ProdID\"]).nunique()[\"ProdDescr\"].eq(1)\n",
    "tmp = tmp[tmp == False].index\n",
    "print(\"N. INCONSISTENT ProdDescr:\", len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have sales with more than 3 digit places?\n",
    "# Result: Yes, we will round them\n",
    "tmp = df[\"Sale\"].astype(str).str.contains(r\",\\d{3,}\")\n",
    "tmp = tmp[tmp == True].index\n",
    "tmp = df.loc[tmp]\n",
    "print(\"INCONSISTENT Sale:\")\n",
    "tmp"
   ]
  },
  {
   "source": [
    "## Data Quality\n",
    "Clean up the datas by correcting semantical errors, removing outliers and other mixed fixes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts sale to float, accomodating the csv format\n",
    "df[\"Sale\"] = df[\"Sale\"].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Remove unidentified customers and converts CustomerID to int\n",
    "df.dropna(subset=['CustomerID'], inplace=True)\n",
    "df[\"CustomerID\"] = df[\"CustomerID\"].astype(int)\n",
    "\n",
    "# Remove entries with strange product's descriptions\n",
    "strange_descr = ['amazon', 'check', 'Dotcom sales', 'reverse 21/5/10 adjustment', 'mouldy, thrown away.', 'found', 'Found', 'label mix up', 'samples/damages', 'thrown away', 'damages', 'showroom', 'wrongly sold as sets', 'dotcom sold sets', 'Amazon sold sets', 'wrongly sold sets', '?sold as sets?', 'damages/display', 'damaged stock', 'damages?', 're dotcom quick fix.', 'sold in set?', 'damaged', 'Damaged', 'Missing', 'adjustment', 'returned', 'wrong code?', 'crushed', 'damages/credits from ASOS.', 'mailout', 'Not rcvd in 10/11/2010 delivery', 'Thrown away-rusty', 'damages/dotcom?', 'smashed', 'reverse previous adjustment', 'incorrectly credited C550456 see 47', 'Next Day Carriage', 'wet damaged', 'Water damaged', 'missing', 'sold as set on dotcom', 'to push order througha s stock was ', 'mix up with c', 'came coded as 20713', 'alan hodge cant mamage this section', 'dotcom', 'ebay', 'Sold as 1 on dotcom', 'Adjust bad debt', 'taig adjust no stock', 'CRUK Commission', '?display?', 'taig adjust', 'allocate stock for dotcom orders ta', 'add stock to allocate online orders', 'test', 'OOPS ! adjustment', 'Dagamed', 'historic computer difference?....se', 'incorrect stock entry.', 'michel oops', 'wrongly coded 20713', 'wrongly coded-23343', 'stock check', 'Wet pallet-thrown away', 'Sale error', 'High Resolution Image', 're-adjustment', 'Amazon', 'Unsaleable, destroyed.', 'dotcom sales', 'had been put aside', 'damages wax', 'wet rusty', 'amazon adjust', 'dotcom adjust', 'check?', 'wet pallet', '???missing', 'wet?', 'lost??', 'wet', 'lost']\n",
    "df = df[~df['ProdDescr'].isin(strange_descr)]\n",
    "\n",
    "# Put all characters in uppercase and remove extra whitespaces for products' description\n",
    "df[\"ProdDescr\"] = df[\"ProdDescr\"].str.upper().str.strip()\n",
    "\n",
    "# Put all characters in uppercase for product ids\n",
    "df[\"ProdID\"] = df[\"ProdID\"].str.upper()\n",
    "\n",
    "# Remove purchases with prices less than or equal to zero, together with some outliers that costs less than 0.01\n",
    "# We remove them since they're few (4)\n",
    "df = df[df[\"Sale\"] >= 0.01]\n",
    "\n",
    "# Remove C from basketIDs, since it is pointless (we already have negative quantities to identify those)\n",
    "# NOTE: We also previously dropped baskets starting with 'A', which had negative sale\n",
    "df[\"BasketID\"] = df[\"BasketID\"].str.replace('C', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform descriptions of same productIDs by taking the longest (more informations)\n",
    "tmp = df.groupby([\"ProdID\"]).nunique()[\"ProdDescr\"].eq(1)\n",
    "tmp = tmp[tmp == False].index\n",
    "new_prod_descr = df[df[\"ProdID\"].isin(tmp)].groupby(\"ProdID\").agg({'ProdDescr': 'max'})\n",
    "\n",
    "def uniform_descr(x):\n",
    "    if x.loc[\"ProdID\"] in new_prod_descr.index:\n",
    "        descr = new_prod_descr.loc[x.loc[\"ProdID\"]][\"ProdDescr\"]\n",
    "        x.loc[\"ProdDescr\"] = descr\n",
    "    return x\n",
    "\n",
    "df[[\"ProdID\", \"ProdDescr\"]] = df[[\"ProdID\", \"ProdDescr\"]].apply(uniform_descr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put multiple products in the same basket as a single product (only those with the same price)\n",
    "df = df.groupby(['BasketID','ProdID', 'Sale']).agg({\n",
    "    'BasketDate': 'min',\n",
    "    'Qta': 'sum',\n",
    "    'CustomerID': 'min',\n",
    "    'CustomerCountry': 'min',\n",
    "    'ProdDescr': 'min'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows corresponding to returns without relative purchase (inconsistent data)\n",
    "invalid_indexes = []\n",
    "def get_invalid_indexes(x):\n",
    "    x = x.sort_values(by='BasketDate')\n",
    "    s = 0\n",
    "    for i, qta in enumerate(x['Qta']):\n",
    "        if (s := s + qta) < 0:\n",
    "            invalid_indexes.append(x.iloc[i].name)\n",
    "            s = 0\n",
    "\n",
    "df[ ~df[\"ProdID\"].isin(['M', 'D', 'BANK CHARGES']) ].groupby(['CustomerID', 'ProdID']).apply(get_invalid_indexes)\n",
    "df.drop(invalid_indexes, inplace=True)"
   ]
  },
  {
   "source": [
    "### OUTLIERS REMOVAL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "def iqr_non_outliers(s: pd.Series):\n",
    "    \"\"\"Returns a true-list of the outliers in a column\n",
    "    of the DataFrame, based on the quantiles\"\"\"\n",
    "    Q1 = s.quantile(0.25)\n",
    "    Q3 = s.quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    trueList = (s < (Q1 - 1.5 * IQR)) | (s > (Q3 + 1.5 * IQR))\n",
    "    return trueList"
   ]
  },
  {
   "source": [
    "### Outliers in ATTRIBUTES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in ATTRIBUTES from QTA\n",
    "df_qta = df[\"Qta\"]\n",
    "\n",
    "plot(df_qta.plot.box(), figsize=(2, 4.8), filename=\"Articles_Qta_BP\")\n",
    "plot(sn.distplot(df_qta[abs(df_qta) < 100], bins=100), filename=\"Articles_Qta_HIST\")\n",
    "\n",
    "# Would IQR be effective?\n",
    "# Result: no, since we think that most of the customers are wholesalers and it would drop too many entries\n",
    "iqr_outliers = df_qta[~iqr_non_outliers(df_qta)]\n",
    "print(\"QTA - IQR RESULTS:\\n\", iqr_outliers.describe())\n",
    "print(\"MIN Qta Positives:\", iqr_outliers[iqr_outliers > 0].min())\n",
    "print(\"MAX Qta Negatives:\", iqr_outliers[iqr_outliers < 0].max())\n",
    "\n",
    "# Search for a threshold\n",
    "plot(df_qta[abs(df_qta) < 10000].plot.box(), figsize=(2, 4.8))\n",
    "plot(df_qta[(df_qta < 3500) & (df_qta > -2000)].plot.box(), figsize=(2, 4.8))\n",
    "\n",
    "# One last check: how are those outliers distributed among the users?\n",
    "outliers_i = df_qta[(df_qta > 3500) | (df_qta < -2000)].index\n",
    "outliers = df.loc[outliers_i]\n",
    "print(\"QTA OUTLIERS (with threshold of 3500):\")\n",
    "print(outliers[\"Qta\"].describe())\n",
    "print(outliers[\"CustomerID\"].nunique())\n",
    "\n",
    "# Values come from different users, we cannot just drop the customers, must instead drop single tuples\n",
    "df.drop(outliers_i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in ATTRIBUTES from SALE\n",
    "df_sale = df['Sale']\n",
    "\n",
    "plot(df_sale.plot.box(), figsize=(2, 4.8), filename=\"Articles_Sale_BP\")\n",
    "plot(sn.distplot(df_sale[df_sale < 50], bins=100), filename=\"Articles_Sale_HIST\")\n",
    "\n",
    "# Search for a threshold and remove based on that\n",
    "plot(df_sale[df_sale < 5000].plot.box(), figsize=(2, 4.8))\n",
    "plot(df_sale[df_sale < 2200].plot.box(), figsize=(2, 4.8))\n",
    "df = df[df_sale < 2200]"
   ]
  },
  {
   "source": [
    "### Outliers in BASKETS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in BASKETS from QTA\n",
    "df_basket_qta = df[[\"BasketID\", \"Qta\"]].groupby(\"BasketID\").agg('sum')[\"Qta\"]\n",
    "\n",
    "plot(df_basket_qta.plot.box(), figsize=(2, 4.8), filename=\"Basket_Sale_BP\")\n",
    "plot(sn.distplot(df_basket_qta[abs(df_basket_qta) < 2000], bins=100), filename=\"Basket_Sale_HIST\")\n",
    "# Result: No outliers found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove in BASKETS from SALE\n",
    "df_basket_cost = df[['BasketID', 'Qta', 'Sale']]\n",
    "df_basket_cost['Cost'] = df_basket_cost['Qta'] * df_basket_cost['Sale']\n",
    "df_basket_cost = df_basket_cost[[\"BasketID\", \"Cost\"]].groupby(\"BasketID\").agg('sum')[\"Cost\"]\n",
    "\n",
    "plot(df_basket_cost.plot.box(), figsize=(2, 4.8), filename=\"Basket_Sale_BP\")\n",
    "plot(sn.distplot(df_basket_cost[(df_basket_cost > -2000) & (df_basket_cost < 6000)], bins=100), filename=\"Basket_Sale_HIST\")\n",
    "\n",
    "# Would IQR be effective?\n",
    "iqr_outliers = df_basket_cost[~iqr_non_outliers(df_basket_cost)]\n",
    "print(\"BASKETID - IQR RESULTS:\\n\", iqr_outliers.describe())\n",
    "print(\"MIN BASKETID-COST Postives:\", iqr_outliers[iqr_outliers > 0].min())\n",
    "print(\"MAX BASKETID-COST Negatives:\", iqr_outliers[iqr_outliers < 0].max())\n",
    "\n",
    "# Search for a threshold\n",
    "plot(df_basket_cost[(df_basket_cost > -8000) & (df_basket_cost < 30000)].plot.box(), figsize=(2, 4.8))\n",
    "\n",
    "# One last check: how are those outliers distributed among the users?\n",
    "outliers = df_basket_cost[(df_basket_cost <= -8000) | (df_basket_cost >= 30000)].index\n",
    "customer_outliers = df[df['BasketID'].isin(outliers)]['CustomerID'].unique()\n",
    "print(\"BASKETID OUTLIERS (WITH THRESHOLD)\")\n",
    "print(\"Baskets outliers:\", len(outliers))\n",
    "print(\"Customers having those baskets:\", len(customer_outliers))\n",
    "\n",
    "# Values come from different users, we cannot just drop the customers, must instead drop single tuples\n",
    "df = df[~df[\"BasketID\"].isin(outliers)]"
   ]
  },
  {
   "source": [
    "### Minor final changes and save the dataset as a secondary data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns with names that could mislead\n",
    "df.rename(columns={'BasketDate': 'PurchaseDate'}, inplace=True)\n",
    "\n",
    "# Swap columns\n",
    "df = df[[\"BasketID\", \"ProdID\", \"ProdDescr\", \"Sale\", \"Qta\", \"PurchaseDate\", \"CustomerID\",\"CustomerCountry\"]]\n",
    "\n",
    "# Sort by date the dataset and reset indexes\n",
    "df.sort_values(\"PurchaseDate\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the pre-processed dataset\n",
    "df.to_csv(\"customer_supermarket_2.csv\")"
   ]
  }
 ]
}