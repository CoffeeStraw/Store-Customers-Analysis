{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "05_pattern_mining_pt2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_4dd_5hvBpc"
      },
      "source": [
        "# DATA MINING PROJECT: Analysis of a Supermarketâ€™s Customers\n",
        "## 4.optional) Pattern Mining with Time Constraints\n",
        "### *Antonio Strippoli, Valerio Mariani*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJcJTVF_vBpk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from functions import *  # Custom function for the analysis\n",
        "from gsp import apriori\n",
        "import datetime\n",
        "import logging\n",
        "from natsort import natsorted\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Set logging\n",
        "logging.basicConfig(level=logging.INFO, filename=\"log.txt\", filemode=\"a+\", format=\"%(message)s\")\n",
        "logging.getLogger().addHandler(logging.StreamHandler())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSvTWS1BvBpl"
      },
      "source": [
        "def plot(ax, folder=\"pattern_mining\", filename=\"\", figsize=(6.4, 4.8)):\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(*figsize)\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        path = os.path.join(\"..\", \"..\", \"report\", \"imgs\", folder)\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "        plt.savefig(os.path.join(path, filename))\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config (which result do we want to analyze)\n",
        "min_baskets = 10\n",
        "min_sup = 0.25\n",
        "\n",
        "# Read result\n",
        "result_set = read_write_result(True, min_baskets, min_sup)\n",
        "result_set = convert_tuples_to_list(result_set)\n",
        "\n",
        "# Compute times\n",
        "df = read_dataset()\n",
        "df = remove_baskets(df, min_baskets)\n",
        "seq_data, time_stamps = sequentialize(df, return_times=True)\n",
        "result_set = compute_patterns_time(result_set, seq_data, time_stamps)\n",
        "\n",
        "# Convert ProdID to ProdDescr\n",
        "result_set = prodID_to_prodDescr(result_set, df)\n",
        "\n",
        "for res in result_set:\n",
        "    print(res[0])\n",
        "    print(res[1], \"-\", len(res[-1]) / len(seq_data))\n",
        "    times = pd.DataFrame(res[-1])\n",
        "    print(times.describe())\n",
        "    plot(times.hist(bins=20))\n",
        "\n",
        "result_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r3pXM5svBpl"
      },
      "source": [
        "### Apply GSP on sequential data using Time Constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config (which result do we want to analyze)\n",
        "min_baskets = 10\n",
        "min_sup = 0.25\n",
        "tests = [\n",
        "    ('min_gap', 'days', list(range(33, -1, -3))),\n",
        "    ('max_gap', 'weeks', list(range(16, 73, 4))),\n",
        "    ('max_span', 'weeks', list(range(16, 93, 4))),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_G2obC4qvBpm",
        "outputId": "9d679ac5-0668-480e-df52-03293735d558"
      },
      "source": [
        "for test in tests:\n",
        "    print(f\"STARTING WITH {test[0]} - {test[1]} - {test[2]}\")\n",
        "    lengths = []\n",
        "    for x in test[2]:\n",
        "        print(f\"TESTING x={x}\")\n",
        "        # Read the dataset\n",
        "        df = read_dataset()\n",
        "        # Remove some baskets\n",
        "        df = remove_baskets(df, min_baskets)\n",
        "        # Convert into seq form\n",
        "        seq_data, time_stamps = sequentialize(df, return_times=True)\n",
        "\n",
        "        # Apply GSP\n",
        "        kwargs = {test[1]: x}\n",
        "        kwargs = {test[0]: datetime.timedelta(**kwargs)}\n",
        "        result_set = apriori(seq_data, min_sup, time_stamps, **kwargs)\n",
        "        \n",
        "        read_write_result(False, min_baskets, min_sup, result_set=result_set, **kwargs)\n",
        "        dist, _ = compute_distribution(result_set, print_out=False)\n",
        "        lengths.append(dist[2] + dist[3])\n",
        "\n",
        "        # DEBUG Prints\n",
        "        if len(lengths) == 1:\n",
        "            print('\\tLEN RESULT SET:', lengths[-1])\n",
        "        elif lengths[-1] != lengths[-2]:\n",
        "            print('\\tLEN RESULT SET:', lengths[-1])\n",
        "        \n",
        "        # Stop when reaching full set\n",
        "        if dist[2] + dist[3] == 17:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# Compute plots for each value tested\n",
        "folder = './gsp_res'\n",
        "for t, x_label, _ in tests:\n",
        "    files = natsorted([f for f in os.listdir(folder) if f.endswith(t.replace('_', '') + '.pickle')])\n",
        "\n",
        "    x, y = [], []\n",
        "    for f in files:\n",
        "        path = os.path.join(folder, f)\n",
        "        number = int(re.search(r'\\_(\\d+)\\D+$', f).group(1))\n",
        "        kwargs = {t: datetime.timedelta(days=number)}\n",
        "        \n",
        "        result_set = read_write_result(True, min_baskets, min_sup, **kwargs)\n",
        "        dist, _ = compute_distribution(result_set, print_out=False)\n",
        "\n",
        "        x.append(number)\n",
        "        y.append(dist[2] + dist[3])\n",
        "    \n",
        "    if x_label == 'weeks':\n",
        "        x = [n // 7 for n in x]\n",
        "    x = [str(n) for n in x]\n",
        "\n",
        "    _, ax = plt.subplots()\n",
        "    ax.plot(x, y)\n",
        "    ax.set(xlabel=x_label.title(), ylabel='N. of sequences')\n",
        "    plot(ax, filename=f\"{t}_trend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config (which result do we want to analyze)\n",
        "min_baskets = 10\n",
        "min_sup = 0.25\n",
        "min_gap = datetime.timedelta(days=30)\n",
        "max_gap = datetime.timedelta(weeks=20)\n",
        "\n",
        "# Read result\n",
        "result_set = read_write_result(True, min_baskets, min_sup, min_gap=min_gap)\n",
        "result_set = convert_tuples_to_list(result_set)\n",
        "compute_distribution(result_set)\n",
        "\n",
        "# Convert ProdID to ProdDescr\n",
        "df = read_dataset()\n",
        "df = remove_baskets(df, min_baskets)\n",
        "result_set = prodID_to_prodDescr(result_set, df)\n",
        "\n",
        "result_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUZ_tzPQvBpm"
      },
      "source": [
        "Forse da buttare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFIeqGUUvBpn"
      },
      "source": [
        "# Config (which result do we want to analyze)\n",
        "min_baskets = 10\n",
        "min_sup = 0.25\n",
        "max_gap = datetime.timedelta(days=365)\n",
        "min_gap = datetime.timedelta(days=365)\n",
        "\n",
        "# Read the dataset\n",
        "df = read_dataset()\n",
        "# Remove some baskets\n",
        "df = remove_baskets(df, min_baskets)\n",
        "# Convert into seq form\n",
        "seq_data, time_stamps = sequentialize(df, return_times=True)\n",
        "\n",
        "# Apply GSP\n",
        "result_set = apriori(seq_data, min_sup, time_stamps, max_span=None, min_gap=None, max_gap=max_gap)\n",
        "compute_distribution(result_set)\n",
        "\n",
        "# Distribution of lengths: {1: 56, 2: 1, 3: 0, 4: 0, 5: 0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heGCl0-gvBpn"
      },
      "source": [
        "params = {\n",
        "    'min_sup': [0.4, 0.35, 0.3, 0.25, 0.2, 0.15],\n",
        "    'min_baskets': [20, 10],\n",
        "    'max_gap': [datetime.timedelta(days=1), datetime.timedelta(days=2), datetime.timedelta(days=3), datetime.timedelta(weeks=1), datetime.timedelta(weeks=2), datetime.timedelta(weeks=3), datetime.timedelta(weeks=4), datetime.timedelta(weeks=8), datetime.timedelta(weeks=12)],\n",
        "    'max_span': [datetime.timedelta(weeks=4), datetime.timedelta(weeks=8), datetime.timedelta(weeks=12), datetime.timedelta(weeks=48)]\n",
        "}\n",
        "for min_sup in params['min_sup']:\n",
        "    for min_baskets in params['min_baskets']:\n",
        "        for max_gap in params['max_gap']:\n",
        "            for max_span in params['max_span']:\n",
        "                logging.info(f\"MIN_BASKETS: {min_baskets}, MIN_SUP: {min_sup}, MAX_GAP: {max_gap}, MAX_SPAN: {max_span}\")\n",
        "\n",
        "                # Read the dataset\n",
        "                df = read_dataset()\n",
        "                # Remove some baskets\n",
        "                df = remove_baskets(df, min_baskets)\n",
        "                # Convert into seq form\n",
        "                seq_data, time_stamps = sequentialize(df, return_times=True)\n",
        "                \n",
        "                # Apply GSP\n",
        "                t0 = time.time()\n",
        "                result_set = apriori(seq_data, min_sup, time_stamps, max_span=max_span, min_gap=None, max_gap=max_gap)\n",
        "                t1 = time.time()\n",
        "\n",
        "                # Compute n. of sequences with len > 2 and n. of sequences containing duplicates\n",
        "                cnt_len_2 = 0\n",
        "                cnt_duplicates = 0\n",
        "                for r in result_set:\n",
        "                    r = r[0]\n",
        "                    tmp = []\n",
        "                    for l in r:\n",
        "                        tmp.extend(l)\n",
        "                    if len(tmp) >= 2:\n",
        "                        cnt_len_2 += 1\n",
        "                        if len(set(tmp)) < len(tmp):\n",
        "                            cnt_duplicates += 1\n",
        "\n",
        "                logging.info(\n",
        "                    f\"TOTAL TIME:\\t{round(t1-t0, 2)} s\\n\"\\\n",
        "                    f\"LEN RESULT SET:\\t{len(result_set)}\\n\"\\\n",
        "                    f\"LEN SEQ > 2:\\t{cnt_len_2}\\nN. DUPLICATES:\\t{cnt_duplicates}\\n\"\n",
        "                )\n",
        "\n",
        "                # Save\n",
        "                save_to_pickle(result_set, min_baskets, min_sup, max_gap.days, max_span.days)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mGJje4OvBpn"
      },
      "source": [
        "compute_distribution(result_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA_N-u3cvBpo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}