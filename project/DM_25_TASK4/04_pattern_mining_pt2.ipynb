{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "05_pattern_mining_pt2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_4dd_5hvBpc"
      },
      "source": [
        "# DATA MINING PROJECT: Analysis of a Supermarketâ€™s Customers\n",
        "## 4.optional) Pattern Mining with Time Constraints\n",
        "### *Antonio Strippoli, Valerio Mariani*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJcJTVF_vBpk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from natsort import natsorted\n",
        "from functions import *  # Custom function for the analysis\n",
        "from gsp import apriori\n",
        "import datetime\n",
        "import logging\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "\n",
        "\n",
        "# Set logging\n",
        "logging.basicConfig(level=logging.INFO, filename=\"log.txt\", filemode=\"a+\", format=\"%(message)s\")\n",
        "logging.getLogger().addHandler(logging.StreamHandler())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSvTWS1BvBpl"
      },
      "source": [
        "def plot(ax, folder=\"pattern_mining\", filename=\"\", figsize=(6.4, 4.8)):\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(*figsize)\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        if not os.path.exists(folder):\n",
        "            os.mkdir(folder)\n",
        "        plt.savefig(os.path.join(folder, filename))\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r3pXM5svBpl"
      },
      "source": [
        "### Apply GSP on sequential data using Time Constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config (which result do we want to analyze)\n",
        "min_baskets = 10\n",
        "min_sup = 0.25\n",
        "tests = [\n",
        "    ('min_gap', 'days', list(range(33, -1, -3))),\n",
        "    ('max_gap', 'weeks', list(range(16, 73, 4))),\n",
        "    ('max_span', 'weeks', list(range(16, 93, 4))),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_G2obC4qvBpm",
        "outputId": "9d679ac5-0668-480e-df52-03293735d558"
      },
      "source": [
        "for test in tests:\n",
        "    print(f\"STARTING WITH {test[0]} - {test[1]} - {test[2]}\")\n",
        "    lengths = []\n",
        "    for x in test[2]:\n",
        "        print(f\"TESTING x={x}\")\n",
        "        # Read the dataset\n",
        "        df = read_dataset()\n",
        "        # Remove some baskets\n",
        "        df = remove_baskets(df, min_baskets)\n",
        "        # Convert into seq form\n",
        "        seq_data, time_stamps = sequentialize(df, return_times=True)\n",
        "\n",
        "        # Apply GSP\n",
        "        kwargs = {test[1]: x}\n",
        "        kwargs = {test[0]: datetime.timedelta(**kwargs)}\n",
        "        result_set = apriori(seq_data, min_sup, time_stamps, **kwargs)\n",
        "        \n",
        "        read_write_result(False, min_baskets, min_sup, result_set=result_set, **kwargs)\n",
        "        dist, _ = compute_distribution(result_set, print_out=False)\n",
        "        lengths.append(dist[2] + dist[3])\n",
        "\n",
        "        # DEBUG Prints\n",
        "        if len(lengths) == 1:\n",
        "            print('\\tLEN RESULT SET:', lengths[-1])\n",
        "        elif lengths[-1] != lengths[-2]:\n",
        "            print('\\tLEN RESULT SET:', lengths[-1])\n",
        "        \n",
        "        # Stop when reaching full set\n",
        "        if dist[2] + dist[3] == 17:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "### Compute plots for each value tested"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder = './gsp_res'\n",
        "for t, x_label, _ in tests:\n",
        "    files = natsorted([f for f in os.listdir(folder) if f.endswith(t.replace('_', '') + '.pickle')])\n",
        "\n",
        "    x, y = [], []\n",
        "    for f in files:\n",
        "        path = os.path.join(folder, f)\n",
        "        number = int(re.search(r'\\_(\\d+)\\D+$', f).group(1))\n",
        "        kwargs = {t: datetime.timedelta(days=number)}\n",
        "        \n",
        "        result_set = read_write_result(True, min_baskets, min_sup, **kwargs)\n",
        "        dist, _ = compute_distribution(result_set, print_out=False)\n",
        "\n",
        "        x.append(number)\n",
        "        y.append(dist[2] + dist[3])\n",
        "    \n",
        "    if x_label == 'weeks':\n",
        "        x = [n // 7 for n in x]\n",
        "    x = [str(n) for n in x]\n",
        "\n",
        "    _, ax = plt.subplots()\n",
        "    ax.plot(x, y)\n",
        "    ax.set(xlabel=x_label.title(), ylabel='N. of sequences')\n",
        "    plot(ax, filename=f\"{t}_trend\")"
      ]
    },
    {
      "source": [
        "### Compute time gaps distribution"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config (which result do we want to analyze)\n",
        "min_baskets = 10\n",
        "min_sup = 0.25\n",
        "\n",
        "# Read result\n",
        "result_set = read_write_result(True, min_baskets, min_sup)\n",
        "result_set = convert_tuples_to_list(result_set)\n",
        "\n",
        "# Load original dataset\n",
        "df = read_dataset()\n",
        "df = remove_baskets(df, min_baskets)\n",
        "seq_data, time_stamps = sequentialize(df, return_times=True)\n",
        "\n",
        "# Compute time gaps between each couple of events\n",
        "result_set = compute_patterns_time(result_set, seq_data, time_stamps)\n",
        "# Convert ProdID to ProdDescr\n",
        "result_set = prodID_to_prodDescr(result_set, df)\n",
        "\n",
        "# Show distributions of time gaps\n",
        "for res in result_set:\n",
        "    print(res[0])\n",
        "    print(res[1], \"-\", len(res[-1]) / len(seq_data))\n",
        "    times = pd.DataFrame(res[-1])\n",
        "    print(times.describe())\n",
        "    plot(times.hist(bins=20))\n",
        "\n",
        "result_set"
      ]
    }
  ]
}